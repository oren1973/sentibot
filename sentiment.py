import requests
from bs4 import BeautifulSoup
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import nltk

nltk.download('vader_lexicon', quiet=True)

analyzer = SentimentIntensityAnalyzer()

def get_sentiment_score(symbol):
    url = f"https://finance.yahoo.com/quote/{symbol}?p={symbol}"
    headers = {
        "User-Agent": "Mozilla/5.0"
    }

    try:
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")
        headlines = soup.find_all("h3")

        scores = []
        for tag in headlines:
            text = tag.get_text().strip()
            if len(text) > 10:
                score = analyzer.polarity_scores(text)["compound"]
                scores.append(score)
                print(f"ğŸ“° '{text}' â†’ {score}")

        if scores:
            avg = round(sum(scores) / len(scores), 3)
            print(f"ğŸ“Š ×××•×¦×¢ ×¡× ×˜×™×× ×˜ ×¢×‘×•×¨ {symbol}: {avg}")
            return avg
        else:
            print("âš ï¸ ×œ× × ××¦××• ×›×•×ª×¨×•×ª ×ª×§×¤×•×ª.")
            return 0.0

    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×¡×¨×™×§×ª ×›×•×ª×¨×•×ª: {e}")
        return 0.0
