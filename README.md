# 📈 Sentibot – מערכת מסחר רגשית אוטונומית (v0.2 - שלב איסוף וכיול)

Sentibot מבצעת איסוף וניתוח סנטימנט יומי אוטומטי עבור מניות נבחרות. המערכת שואבת מידע מכותרות פיננסיות ומרשתות חברתיות (Reddit), מנתחת את הרגש, מקבלת החלטת מסחר תיאורטית (BUY/SELL/HOLD), מבצעת פקודות מסחר (כרגע ב-Paper Trading דרך Alpaca API עבור החלטות BUY וסגירת פוזיציות BUY), שומרת תיעוד מפורט ומצטבר, ושולחת סיכום יומי במייל.

**מטרת העל:** פיתוח מערכת אוטונומית לחלוטין, המסוגלת לבצע מסחר רווחי ועקבי בשוק ההון על בסיס ניתוח סנטימנט מתקדם ולמידת מכונה.

---

## ⚙️ רכיבי המערכת העיקריים

| קובץ                      | תפקיד                                                                                                                               |
|---------------------------|-------------------------------------------------------------------------------------------------------------------------------------|
| `main.py`                 | סקריפט ההרצה הראשי: מנהל את התהליך היומי לכל סמל – איסוף מידע, ניתוח סנטימנט, קבלת החלטה, ביצוע מסחר (Paper), תיעוד ושליחת מייל.    |
| `settings.py`             | קובץ הגדרות מרכזי: כולל הגדרות Logger, תצורת מקורות חדשות (NEWS_SOURCES_CONFIG), משקלים, ספי החלטה, פרמטרים ל-Reddit ו-Alpaca, ונתיבים. |
| `smart_universe.py`       | מגדיר את רשימת סימולי המניות (`SYMBOLS`) למעקב.                                                                                         |
| `news_aggregator.py`      | מאגד איסוף כותרות ממקורות חדשות שונים (Yahoo, CNBC וכו') המוגדרים ב-`settings.py`.                                                       |
| `yahoo_scraper.py`        | Scraper ייעודי לשליפת כותרות מ-Yahoo Finance (דרך RSS).                                                                                |
| `cnbc_scraper.py`         | Scraper ייעודי לשליפת כותרות מ-CNBC (דרך RSS כללי וסינון מילות מפתח).                                                                      |
| `investors_scraper.py`    | Scraper ייעודי לשליפת כותרות מ-Investors.com (דרך RSS, **מנוטרל כרגע**).                                                                  |
| `marketwatch_scraper.py`  | Scraper ייעודי לשליפת כותרות מ-MarketWatch (באמצעות Web Scraping, **מנוטרל כרגע**).                                                       |
| `reddit_scraper.py`       | Scraper ייעודי לשליפת פוסטים ותגובות רלוונטיים מ-Reddit.                                                                              |
| `sentiment_analyzer.py`   | מבצע ניתוח סנטימנט על טקסטים באמצעות VADER, עם יכולת שקלול ציון לפי משקל המקור (מ-`settings.py`).                                      |
| `recommender.py`          | מקבל ציון סנטימנט ממוצע ומחליט על BUY/SELL/HOLD לפי ספים המוגדרים ב-`settings.py`.                                                      |
| `alpaca_trader.py`        | אחראי על שליחת פקודות BUY ו-SELL (לסגירת פוזיציות BUY) ל-Alpaca API (כרגע מחובר ל-Paper Trading).                                     |
| `email_sender.py`         | שולח מיילים עם סיכומי הרצה וקבצים מצורפים.                                                                                             |
| `sentibot_reports/` (תיקייה) | תיקייה שבה נשמרים הדוחות:                                                                                                              |
| `  learning_log_cumulative.csv` | לוג מצטבר של כל הרשומות פר סמל ופר הרצה, כולל סנטימנטים, החלטות וביצועי מסחר. **קובץ המפתח ללמידה עתידית.**                     |
| `  detailed_headlines_YYYYMMDD_HHMMSS.csv` | דוח מפורט (פר הרצה) של כל כותרת/פוסט, המקור והסנטימנט שחושב.                                                              |
| `  summary_decisions_YYYYMMDD_HHMMSS.csv`  | דוח סיכום (פר הרצה) של הסנטימנט הממוצע, ההחלטה, והאם בוצעה פעולת מסחר לכל סמל. **נשלח במייל.**                             |
| `performance_analyzer.py` | (קיים אך דורש שדרוג) מיועד לניתוח ביצועי מסחר בדיעבד.                                                                                    |

---

## 🔁 תהליך יומי מעודכן (`main.py`)

1.  **אתחול:** טעינת הלוג המצטבר (`learning_log_cumulative.csv`) או יצירתו אם לא קיים.
2.  **לולאה על כל סמל (`symbol`) מתוך `SYMBOLS` (המוגדרים ב-`smart_universe.py`):**
    א.  **איסוף מידע:**
        i.  קריאה ל-`fetch_all_news` (מ-`news_aggregator.py`) לאיסוף כותרות ממקורות החדשות המאופשרים (Yahoo, CNBC וכו').
        ii. אם מאופשר ב-`settings.py`, קריאה ל-`get_reddit_posts` (מ-`reddit_scraper.py`) לאיסוף תוכן רלוונטי מ-Reddit.
        iii. איחוד כל הטקסטים שנאספו.
    ב.  **ניתוח סנטימנט:**
        i.  לולאה על כל טקסט שנאסף.
        ii. קריאה ל-`analyze_sentiment` עם הטקסט ושם המקור כדי לקבל ציון סנטימנט משוקלל.
        iii. שמירת פרטי כל טקסט וציונו לדוח המפורט היומי.
    ג.  **קבלת החלטה:**
        i.  חישוב ממוצע ציוני הסנטימנט המשוקללים עבור הסמל הנוכחי.
        ii. חישוב סטטיסטיקות נוספות (סטיית תקן, מקור דומיננטי).
        iii. קריאה ל-`make_recommendation` עם הסנטימנט הממוצע לקבלת החלטת BUY/SELL/HOLD.
    ד.  **ביצוע מסחר (Paper Trading):**
        i.  שליפת ההחלטה האחרונה שנרשמה עבור הסמל מה-`learning_log_cumulative.csv`.
        ii. אם ההחלטה הנוכחית היא BUY והיא שונה מהקודמת -> קריאה ל-`trade_stock` לביצוע קנייה.
        iii. אם ההחלטה הנוכחית היא SELL וההחלטה הקודמת הייתה BUY -> קריאה ל-`trade_stock` לביצוע מכירה (סגירת פוזיציה). (כרגע לא מתבצע Short Selling).
    ה.  **תיעוד ללוג המצטבר:**
        i.  שמירת רשומה חדשה ב-`learning_log_cumulative.csv` עם כל הפרטים: run_id, symbol, datetime, sentiment_avg, sentiment_std, num_articles, main_source, decision, previous_decision, trade_executed, ופרטי ציונים גולמיים.
3.  **סיום הרצה:**
    א.  שמירת הדוחות היומיים (`detailed_headlines...` ו-`summary_decisions...`).
    ב.  שליחת מייל עם קובץ הסיכום היומי (`summary_decisions...`) מצורף.

---

## 📂 מבנה הקובץ `learning_log_cumulative.csv` (מעודכן)

| עמודה                  | הסבר                                                                                                                            |
|-------------------------|---------------------------------------------------------------------------------------------------------------------------------|
| `run_id`                | מזהה ריצה ייחודי (מבוסס חותמת זמן).                                                                                                |
| `symbol`                | סימול המניה.                                                                                                                      |
| `datetime`              | חותמת הזמן של תחילת עיבוד הסמל בריצה זו.                                                                                           |
| `sentiment_avg`         | ממוצע ציוני הסנטימנט המשוקללים (מכל הפריטים שנאספו לסמל זה).                                                                     |
| `sentiment_std`         | סטיית התקן של ציוני הסנטימנט (מדד לפיזור/קונצנזוס).                                                                                |
| `num_total_articles`    | סך כל הפריטים (כותרות/פוסטים/תגובות) שנותחו עבור הסמל בריצה זו.                                                                       |
| `main_source_overall`   | המקור שממנו הגיעו רוב הפריטים שנותחו לסמל זה (למשל, "Reddit_Comment", "CNBC").                                                     |
| `decision`              | ההחלטה הנוכחית שהתקבלה (BUY/SELL/HOLD).                                                                                            |
| `previous_decision`     | ההחלטה האחרונה שנרשמה בלוג המצטבר עבור אותו סמל.                                                                                    |
| `trade_executed`        | בוליאני (True/False) – האם נשלחה פקודת מסחר ל-Alpaca כתוצאה מההחלטה.                                                                 |
| `raw_scores_details`    | מחרוזת (אולי JSON בעתיד) המכילה רשימה של כל ציוני הסנטימנט הבודדים והמקורות שלהם, ששימשו לחישוב הממוצע. (לניתוח עומק בעתיד). |
| *עמודות עתידיות:*       | `price_at_decision`, `price_at_execution`, `trade_result_Xdays`, `pct_change_Xdays` (יגיעו משילוב `performance_analyzer`).       |

---

## 📊 סטטוס נוכחי (נכון ל-יוני 2024)

**הצלחות וחוזקות:**

*   **תשתית איסוף נתונים מודולרית:** קיימים Scrapers למספר מקורות (CNBC, Yahoo, Reddit עובדים. Investors, MarketWatch מנוטרלים זמנית).
*   **איסוף תוכן עשיר מ-Reddit:** כולל פוסטים ותגובות מובילות.
*   **ניתוח סנטימנט עם שקלול:** VADER עם יכולת לתת משקלים שונים למקורות מידע (מוגדר ב-`settings.py`).
*   **מנגנון המלצות בסיסי:** מבוסס ספים (דורש כיול).
*   **ביצוע מסחר (Paper Trading):** חיבור ל-Alpaca API, ביצוע פקודות BUY וסגירת פוזיציות BUY. מניעת Short Selling לא רצוי.
*   **תיעוד מקיף:**
    *   לוג מצטבר (`learning_log_cumulative.csv`) נשמר וצובר נתונים.
    *   דוחות יומיים מפורטים וסיכומי החלטות נשמרים.
*   **מערכת לוגינג (Logging) מפורטת:** מאפשרת מעקב ודיבאגינג.
*   **שליחת עדכונים במייל:** סיכום יומי נשלח עם דוח מצורף.
*   **יציבות טכנית:** המערכת רצה מתחילתה ועד סופה ומטפלת בשגיאות בצורה סבירה.

**בעיות ידועות וחולשות:**

*   **תלות גבוהה ב-Reddit:** רוב הנתונים מגיעים כרגע מ-Reddit. מקורות חדשות "מסורתיים" (Yahoo, CNBC) מספקים מעט נתונים, ואחרים (Investors, MarketWatch) נחסמים או עם פידים בעייתיים.
*   **כיול ספים ומשקלים:** הספים ב-`recommender.py` והמשקלים למקורות ב-`settings.py` הם ראשוניים ודורשים כיול מבוסס נתונים וביצועים.
*   **ניתוח ביצועים חסר (בתוך הלוג המצטבר):** ה-`learning_log_cumulative.csv` עדיין לא מכיל מידע על ביצועי השוק בפועל לאחר ההחלטות.
*   **איכות ניתוח הסנטימנט (VADER):** VADER הוא כלי גנרי. סנטימנט פיננסי דורש ניואנסים שאולי לא נתפסים היטב.
*   **ניהול פוזיציות בסיסי:** אין עדיין בדיקה אקטיבית של הפוזיציות הקיימות ב-Alpaca לפני כל החלטת מסחר (מעבר למניעת Short).
*   **מערכת הקבצים ב-Render:** קבצים שנשמרים עלולים להיות זמניים. יש צורך בפתרון אחסון קבוע (Persistent Disk) לטווח ארוך.

---

## 🟦 תכנית אסטרטגית לשלבים הבאים (MVP לצבירת נתונים בעלי ערך -> מערכת לומדת)

**שלב 1: ייצוב ושיפור איסוף הנתונים ובסיס ללמידה (טווח קצר-בינוני)**

1.  **המשך הרצות יומיות סדירות:** לצבירת נתונים ב-`learning_log_cumulative.csv`.
2.  **שדרוג ואינטגרציה של `performance_analyzer.py` (עדיפות גבוהה):**
    *   להתאים אותו לקרוא את `learning_log_cumulative.csv`.
    *   עבור כל רשומה רלוונטית (שבוצעה בה פעולה או כל החלטה), לשלוף מחירי שוק היסטוריים (דרך Alpaca API) בנקודת ההחלטה/ביצוע ולאחר X ימי עסקים.
    *   לחשב אחוזי שינוי ולקבוע "הצלחה" של ההחלטה.
    *   **להוסיף את נתוני הביצוע האלה כעמודות חדשות לקובץ `learning_log_cumulative.csv` הקיים.**
    *   ליצור דוח ביצועים מסכם חדש.
3.  **שיפור מקורות המידע:**
    *   לחקור למה Yahoo Finance מספק מעט נתונים ולנסות פידים אחרים.
    *   לחפש ולהוסיף 1-2 מקורות RSS/API אמינים נוספים לחדשות פיננסיות.
    *   לנסות לפתור את בעיית החסימה מ-MarketWatch (למשל, User-Agents שונים, ואם לא עוזר – לשקול הסרתו).
4.  **הטמעת Persistent Disk ב-Render:** להבטחת שמירת הנתונים והלוגים לאורך זמן.

**שלב 2: כיול ראשוני ובניית יכולות Backtesting (טווח בינוני)**

1.  **ניתוח ראשוני של `learning_log_cumulative.csv` המעודכן (עם נתוני ביצועים):**
    *   זיהוי קורלציות בין סנטימנט (ממוצע, std, מקורות) לבין ביצועי מניות.
    *   הערכה ראשונית של אילו סמלים/מקורות נותנים אותות טובים יותר.
2.  **כיול ספי ה-Recommender ומשקלי המקורות:** על סמך הניתוח.
3.  **בניית תשתית Backtesting בסיסית:**
    *   יכולת להריץ את לוגיקת הליבה של המערכת על נתונים היסטוריים (סנטימנט היסטורי, אם ניתן לשחזר, או על בסיס `learning_log` קיים).
    *   לבדוק איך שינויי פרמטרים (ספים, משקלים) היו משפיעים על ביצועי העבר.
4.  **שילוב מדדי שוק נוספים:** הוספת מחיר ו-Volume בזמן ההחלטה ל-`learning_log` ולניתוח.

**שלב 3: מעבר ללמידת מכונה (ML) ואופטימיזציה (טווח ארוך)**

1.  **הנדסת פיצ'רים (Feature Engineering):** יצירת פיצ'רים נוספים מנתוני הסנטימנט והשוק.
2.  **אימון מודלי ML ראשונים:**
    *   שימוש ב-`learning_log_cumulative.csv` כ-Dataset.
    *   התחלה עם מודלים פשוטים (רגרסיה לוגיסטית, עצי החלטה) לחיזוי כיוון מחיר או להחלטת BUY/SELL/HOLD.
    *   החלפת ה-`recommender.py` מבוסס הכללים במודל ה-ML.
3.  **מערכת למידה אוטונומית (משוב ואימון מחדש):**
    *   תהליך אוטומטי לאימון מחדש של המודלים על נתונים חדשים.
    *   אלגוריתמים לאופטימיזציה של משקלי מקורות ופרמטרים אחרים על סמך ביצועים.
4.  **בחירת יקום מניות דינמי:** מנגנון שיכול להוסיף/להסיר מניות למעקב על סמך פוטנציאל וביצועים.
5.  **UI גרפי (אופציונלי):** להצגת ביצועים, החלטות, ונתונים בצורה ויזואלית.

---

## 🛠️ קונפיגורציה נדרשת

**משתני סביבה (להגדרה ב-Render):**

```bash
# פרטי Alpaca API (עבור Paper Trading או Live Trading)
ALPACA_API_KEY="YOUR_PAPER_API_KEY" # או מפתח חי
ALPACA_SECRET_KEY="YOUR_PAPER_SECRET_KEY" # או סוד חי

# פרטי מייל לשליחת דוחות
EMAIL_USER="your_gmail_address@gmail.com"
EMAIL_PASS="your_gmail_app_password_or_regular_password" # עדיף App Password
EMAIL_RECEIVER="recipient_email_address@example.com"

# פרטי Reddit API (חובה אם REDDIT_ENABLED=True)
REDDIT_CLIENT_ID="your_reddit_client_id"
REDDIT_CLIENT_SECRET="your_reddit_client_secret"
REDDIT_USER_AGENT="Sentibot/0.3 by YourUniqueBotName" # חשוב שיהיה ייחודי!

# (אופציונלי) אפשר להגדיר גם את רשימת הסאברדיטים ומגבלות Reddit כמשתני סביבה
# REDDIT_SUBREDDITS_LIST="stocks,wallstreetbets,finance"
# REDDIT_LIMIT_PER_SUBREDDIT="10"
# REDDIT_COMMENTS_PER_POST="2"
הגדרות עיקריות בקובץ settings.py:
NEWS_SOURCES_CONFIG: הגדרת מקורות החדשות, ה-URL שלהם, הפונקציה המתאימה, והאם הם מאופשרים (enabled), והמשקל שלהם (weight).
SYMBOLS (מיובא מ-smart_universe.py): רשימת המניות למעקב.
RECOMMENDER_THRESHOLD_BUY, RECOMMENDER_THRESHOLD_SELL: ספי ההחלטה.
פרמטרים של Reddit (אם לא מוגדרים כמשתני סביבה).
נתיבים לקבצים ופרמטרים כלליים נוספים.
