# main.py (专住 注转 转转)

import os
import sys
import pandas as pd
from datetime import datetime
import logging #  logging

# ---   砖 专转 ---
from settings import setup_logger, NEWS_SOURCES_CONFIG #  砖-NEWS_SOURCES_CONFIG 拽 -settings
#  SYMBOLS 专 -smart_universe.py:
from smart_universe import SYMBOLS 
#  转 专爪 砖转砖  转 砖专 -settings:
from settings import DEFAULT_MAX_HEADLINES_PER_SOURCE #  砖砖  *驻专 拽专* -news_aggregator
#  *转* -main.py 驻砖专 专    -settings
MAIN_MAX_TOTAL_HEADLINES = 50 

#  砖砖 砖 拽抓  驻拽爪 转  砖砖 
from news_aggregator import fetch_all_news 
from sentiment_analyzer import analyze_sentiment
from recommender import make_recommendation
#  砖-email_sender.py  驻拽爪 拽转
from email_sender import send_run_success_email 

# 转 专 专砖 砖 驻拽爪
# 转  拽专 -setup_logger 专拽 驻注 转 专转 驻拽爪  转专爪,
#  转 转   注 __name__ 驻 砖注砖.
# , 爪专 专 住驻爪驻 -main.
logger = setup_logger("SentibotMain")

def main(force_run: bool = False): # 住驻转 Type Hint -force_run
    run_id_str = datetime.now().strftime("%Y%m%d_%H%M%S") # ID 专爪 转
    logger.info(f" Starting Sentibot run ID: {run_id_str}")

    # 专砖 住祝  转 转专转 爪 住 砖
    all_individual_headline_analysis = []
    # 专砖 住祝 住 驻专 住 (住 爪注 )
    aggregated_symbol_analysis = []

    if not SYMBOLS or not isinstance(SYMBOLS, list) or len(SYMBOLS) == 0:
        logger.critical("SYMBOLS list is not defined, empty, or not a list. Exiting application.")
        #  驻砖专 砖拽 砖转  砖  专爪
        return

    logger.info(f"Processing symbols: {', '.join(SYMBOLS)}")

    for symbol in SYMBOLS:
        logger.info(f"--- Processing symbol: {symbol} ---")
        try:
            # 拽专 驻拽爪 转 -news_aggregator
            #  专 list[tuple[str, str]] 专 [(title1, source1), (title2, source2), ...]
            # -DEFAULT_MAX_HEADLINES_PER_SOURCE -settings 砖驻注 转 fetch_all_news
            # 注  转专转 拽转  拽专 *驻* 住 住驻 砖 驻转.
            # -MAIN_MAX_TOTAL_HEADLINES  砖 注  住  转专转 注 -main.py.
            headlines_data_from_aggregator = fetch_all_news(symbol, max_headlines_total=MAIN_MAX_TOTAL_HEADLINES)

            if not headlines_data_from_aggregator:
                logger.warning(f"No headlines found for '{symbol}' after aggregation and filtering in news_aggregator.")
                continue

            logger.info(f"Received {len(headlines_data_from_aggregator)} headlines for '{symbol}' from aggregator to analyze.")
            
            current_symbol_sentiments = [] # 专砖 住祝 爪 住 注专 住 

            #  注专转 注 专砖转 -tuples 砖转拽
            for title_text, source_name in headlines_data_from_aggregator:
                logger.debug(f"  Analyzing: [{source_name}] '{title_text[:80]}...'")
                try:
                    # 注专转 拽住 砖 拽专 驻拽爪转 转 住
                    # 驻拽爪 转专 爪 砖拽 ( None  砖 砖)
                    sentiment_score = analyze_sentiment(text=title_text, source_name=source_name)
                    
                    if sentiment_score is not None:
                        all_individual_headline_analysis.append({
                            "run_id": run_id_str,
                            "symbol": symbol,
                            "source": source_name,
                            "title": title_text,
                            "sentiment_score": sentiment_score, # 砖 注 注拽
                            "analysis_timestamp": datetime.now().isoformat()
                        })
                        current_symbol_sentiments.append(sentiment_score)
                    else:
                        logger.warning(f"Sentiment analysis returned None for title from '{source_name}' for '{symbol}'.")
                
                except Exception as e_sentiment:
                    #  砖 砖 住驻爪驻转 转 住
                    logger.error(f"Error during sentiment analysis for title from '{source_name}' for '{symbol}': '{title_text[:50]}...'. Error: {e_sentiment}", exc_info=False) # exc_info=False   爪祝  砖 专 

            if not current_symbol_sentiments:
                logger.warning(f"No sentiment scores were successfully calculated for '{symbol}'. Skipping recommendation.")
                continue #  砖  砖  (住 )
            
            # 砖 住 爪注 住 注 住住 爪 砖拽
            avg_sentiment_for_symbol = sum(current_symbol_sentiments) / len(current_symbol_sentiments)
            logger.info(f"Average sentiment score for '{symbol}': {avg_sentiment_for_symbol:.4f} (based on {len(current_symbol_sentiments)} analyzed headlines)")

            # --- 拽转 爪 ---
            # 砖:  砖住驻 -recommender.py 转 住拽 砖 avg_sentiment_for_symbol!
            #  avg_sentiment_for_symbol  爪注 砖 爪 砖拽 (砖 转 > 1),
            #  住驻 拽专 砖 0.2 - -0.2  转.
            #  专注 砖-recommender.py 注 转 注   砖住驻 转.
            recommendation_output = make_recommendation(avg_sentiment_for_symbol)
            trade_decision = recommendation_output.get("decision", "ERROR_NO_DECISION")
            
            logger.info(f"Recommendation for '{symbol}': {trade_decision} (Score: {avg_sentiment_for_symbol:.4f})")
            
            # 住祝 转 住 驻专 住
            aggregated_symbol_analysis.append({
                "run_id": run_id_str,
                "symbol": symbol,
                "avg_sentiment_score": avg_sentiment_for_symbol,
                "num_analyzed_headlines": len(current_symbol_sentiments),
                "trade_decision": trade_decision, # 砖 注 注拽
                "processing_datetime": datetime.now().isoformat()
            })

            # --------------------------------------------------------------------
            #  拽 住祝 拽 砖 住专  专爪:
            # 1. 拽专转  拽转 -learning_log.csv 住专.
            # 2. 砖  转 (trade_decision).
            # 3.  砖 砖  BUY  SELL -> 拽专 -alpaca_trader.trade_stock(symbol, trade_decision).
            # 4. 砖专转  驻专 -learning_log.csv 爪专.
            # 专注, 拽       转 拽 -main 专 砖砖转驻转.
            # --------------------------------------------------------------------

        except Exception as e_symbol_processing:
            logger.error(f"A critical error occurred while processing symbol '{symbol}': {e_symbol_processing}", exc_info=True)
            # 砖 住     砖

    # --- 砖专转 转 CSV 住祝 专爪 ---
    output_dir = "sentibot_reports" # 转拽 砖专转 转
    try:
        os.makedirs(output_dir, exist_ok=True) # 爪专 转 转拽    拽转
        logger.info(f"Reports will be saved to directory: {output_dir}")
    except OSError as e_dir:
        logger.error(f"Could not create reports directory '{output_dir}': {e_dir}. Saving to current directory.")
        output_dir = "." # 砖专 转拽 转  爪专转 转拽 砖

    #  驻专 砖  转专转 住
    if all_individual_headline_analysis:
        detailed_report_df = pd.DataFrame(all_individual_headline_analysis)
        detailed_report_filename = f"detailed_headlines_{run_id_str}.csv"
        detailed_report_filepath = os.path.join(output_dir, detailed_report_filename)
        try:
            detailed_report_df.to_csv(detailed_report_filepath, index=False, encoding='utf-8-sig')
            logger.info(f" Saved detailed headline analysis report: {detailed_report_filepath}")
        except Exception as e_save_detail:
            logger.error(f"Failed to save detailed report to '{detailed_report_filepath}': {e_save_detail}")
    else:
        logger.warning("No individual headline data was collected in this run. Detailed report will not be generated.")

    #  住 驻专 住 注 住 爪注 
    path_to_email_attachment = None
    if aggregated_symbol_analysis:
        summary_report_df = pd.DataFrame(aggregated_symbol_analysis)
        summary_report_df = summary_report_df.sort_values(by="avg_sentiment_score", ascending=False) #  驻 住
        
        summary_report_filename = f"summary_decisions_{run_id_str}.csv"
        summary_report_filepath = os.path.join(output_dir, summary_report_filename)
        path_to_email_attachment = summary_report_filepath # 砖专转 转 砖 
        try:
            summary_report_df.to_csv(summary_report_filepath, index=False, encoding='utf-8-sig')
            logger.info(f" Saved aggregated symbol analysis report: {summary_report_filepath}")
        except Exception as e_save_summary:
            logger.error(f"Failed to save summary report to '{summary_report_filepath}': {e_save_summary}")
            path_to_email_attachment = None #  砖专 砖,  转住 砖 拽抓 砖 拽
    else:
        logger.info("No aggregated symbol analysis data to save. Summary report will not be generated.")

    # --- 砖转  住 ---
    #  砖驻拽爪 send_run_success_email 转 拽转
    if 'send_run_success_email' in globals() and callable(send_run_success_email):
        logger.info(f"Attempting to send summary email for run ID: {run_id_str}...")
        email_sent_successfully = send_run_success_email(
            run_id_str=run_id_str, 
            attachment_path=path_to_email_attachment # 砖   path_to_email_attachment  None
        )
        if email_sent_successfully:
            logger.info(f" Summary email for run {run_id_str} sent/attempted successfully.")
        else:
            logger.error(f" Failed to send summary email for run {run_id_str}.")
    else:
        logger.warning("Function 'send_run_success_email' not found or not callable. Summary email not sent.")

    logger.info(f" Sentibot run ID {run_id_str} finished.")

if __name__ == "__main__":
    # --- 专转 专爪 拽转  专 CLI ---
    # (驻砖专 住祝 注转 .env  驻转 拽)
    # from dotenv import load_dotenv
    # load_dotenv()
    
    # 专转 专转  转 拽转  注砖转 .
    # 砖,  专爪 专转 注转 DEBUG 砖专爪 转:
    # 砖专  转专 转 专 专砖 砖 驻拽爪 专转 DEBUG.
    #  砖驻注 专拽  专  专  专住 转  注 专  转专 ( INFO).
    # main_execution_logger = setup_logger("SentibotMain", level=logging.DEBUG)
    # main_execution_logger.info("Running main() with overall DEBUG level logging for SentibotMain.")
    
    # 拽  砖 专 "force" -command line
    force_run_param = False
    if len(sys.argv) > 1 and sys.argv[1].lower() == "force":
        logger.info("Force run argument detected via command line.") # 砖转砖 专 砖专 注
        force_run_param = True
    
    main(force_run=force_run_param)
