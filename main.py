# main.py
import time
from sentiment_analyzer import analyze_sentiment
from yahoo_scraper import get_yahoo_news
from investors_scraper import get_investors_news
from reddit_scraper import get_reddit_posts
from recommender import make_recommendation

SYMBOLS = [
    "AAPL", "TSLA", "NVDA", "MSFT", "META",
    "PFE", "XOM", "JPM", "DIS", "WMT"
]

print("ğŸš€ Sentibot v1.5 â€“ ××•×¤×¢×œ âœ…")

for symbol in SYMBOLS:
    print(f"ğŸ” ××—×©×‘ ×¡× ×˜×™×× ×˜ ×¢×‘×•×¨ {symbol}...")

    # ×§×‘×œ×ª ×ª×•×›×Ÿ ×××§×•×¨×•×ª ×©×•× ×™×
    yahoo_articles = get_yahoo_news(symbol)
    investors_articles = get_investors_news(symbol)
    reddit_posts = get_reddit_posts(symbol)

    all_articles = yahoo_articles + investors_articles + reddit_posts

    if not all_articles:
        print(f"âš ï¸ ×œ× × ××¦××• ×›×ª×‘×•×ª ××• ×¤×•×¡×˜×™× ×¢×‘×•×¨ {symbol}")
        continue

    # × ×™×ª×•×— ×¡× ×˜×™×× ×˜
    sentiments = []
    for text in all_articles:
        score = analyze_sentiment(text)
        sentiments.append(score)
        print(f"ğŸ“° '{text[:80]}...' â†’ {score:.4f}")

    avg_sentiment = sum(sentiments) / len(sentiments)
    result = make_recommendation(avg_sentiment)

    print(f"ğŸ“Š {symbol}: ×¡× ×˜×™×× ×˜ ××©×•×§×œ×œ: {avg_sentiment:.3f}")
    print(f"ğŸ“Š {symbol}: ×”×—×œ×˜×”: {result['decision'].upper()}")

    time.sleep(1)

print("âœ… ×”×¡×ª×™×™× ×‘×”×¦×œ×—×”.")
